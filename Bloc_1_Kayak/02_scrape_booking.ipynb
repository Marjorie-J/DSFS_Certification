{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecceb386",
   "metadata": {},
   "source": [
    "Scrape le site booking.com pour avoir le Top 20 des hôtels par ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da2526b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 16:53:22 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: scrapybot)\n",
      "2025-04-27 16:53:22 [scrapy.utils.log] INFO: Versions: lxml 5.3.1.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.10.0, w3lib 2.1.2, Twisted 23.10.0, Python 3.12.3 | packaged by conda-forge | (main, Apr 15 2024, 18:20:11) [MSC v.1938 64 bit (AMD64)], pyOpenSSL 24.2.1 (OpenSSL 3.5.0 8 Apr 2025), cryptography 43.0.0, Platform Windows-11-10.0.26100-SP0\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 89966b3cfd1fa850\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6058\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: e209d704d3cb6348\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6059\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 910afca300bb09c7\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6060\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 3b676a07b40b51d2\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6061\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: ae18f943a8a70722\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6062\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 1493b1d1508e081f\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6063\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 517471a322bd70ce\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6064\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 76e5c7040f15ae2a\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6065\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: c3ddd3133fa24cd3\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6066\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 81298979d4ea82df\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6067\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 27da7ce69723267e\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6068\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: f32f4d30d44777ab\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6069\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: e19eb6f0b53240bc\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6070\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: b8e4a076de410298\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6071\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: f1b739abf84da880\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6072\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: fe32b8cfe9cf7a1f\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6073\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 3b653ebabbddf930\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D842330>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 7750339acaa0a4da\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D85F1A0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: d531ce8ca9558daa\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:22 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D8D43B0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:22 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.extensions.telnet] INFO: Telnet Password: 9f7b2f09acfef98d\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:22 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:22 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:22 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D8B8B90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 83ef62546cfa8d09\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9047D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: d35b535ae9a1b2ff\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9155E0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 7a97b6bfa49f9fa3\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9162D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 6e0f313ff4529b6d\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9532C0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 614877d983eb15ef\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D96BB60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: e0755b03f9d22f38\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D999220>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 333b121f50ef16ab\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D99B6B0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: ec2c94f098384832\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9C8A40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 7a623081c1b613d2\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9E19D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 2c4ecdd70bd6d0bc\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9F6B10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 58d82dbee2ccb8ab\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA13C50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 8428faf11c7370d6\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA40CB0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 9e14a25c5d207467\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9F7C80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 2471833eb0cd8be7\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA53140>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:53:23 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.extensions.telnet] INFO: Telnet Password: 0a9808e41f7b8fd5\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2025-04-27 16:53:23 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 20, 'USER_AGENT': 'Chrome/97.0'}\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2025-04-27 16:53:23 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2025-04-27 16:53:23 [scrapy.core.engine] INFO: Spider opened\n",
      "2025-04-27 16:53:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2025-04-27 16:53:23 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.start_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA73A70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1334, in startListening\n",
      "    skt.bind(addr)\n",
      "OSError: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 67, in start_listening\n",
      "    self.port: Port = listen_tcp(self.portrange, self.host, self)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\reactor.py\", line 41, in listen_tcp\n",
      "    return reactor.listenTCP(x, factory, interface=host)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\posixbase.py\", line 364, in listenTCP\n",
      "    p.startListening()\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\twisted\\internet\\tcp.py\", line 1336, in startListening\n",
      "    raise CannotListenError(self.interface, self.port, le)\n",
      "twisted.internet.error.CannotListenError: Couldn't listen on 127.0.0.1:6073: [WinError 10048] Une seule utilisation de chaque adresse de socket (protocole/adresse réseau/port) est habituellement autorisée.\n",
      "2025-04-27 16:54:03 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:03 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29519,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6049697,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.066377,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 3, 968803, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30795532,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 19,\n",
      " 'log_count/INFO': 172,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 902426, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:03 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:03 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D842330>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:03 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:03 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:03 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29768,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6282676,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.38686,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 3, 984765, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31340978,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 326,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 597905, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:03 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 30420,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6007007,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.786453,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 537197, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30240865,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 250,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 750744, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29748,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6042701,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.993185,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 648598, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30807041,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 304,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 655413, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29710,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5988306,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.784247,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 653161, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30154016,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 208,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 868914, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29911,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5986964,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.709813,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 660426, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30181390,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 19,\n",
      " 'log_count/INFO': 183,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 950613, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D85F1A0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29923,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5917821,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.441042,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 679598, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29196558,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 6,\n",
      " 'log_count/INFO': 61,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 238556, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA40CB0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29781,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6280538,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.055266,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 685821, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31322199,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 22,\n",
      " 'log_count/INFO': 330,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 630555, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29465,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6140668,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.022646,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 693701, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32163051,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 22,\n",
      " 'log_count/INFO': 314,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 671055, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29758,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6028565,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.512789,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 693701, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30579718,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 10,\n",
      " 'log_count/INFO': 100,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 180912, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9E19D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29136,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5940928,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.510567,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 707734, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29213993,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 10,\n",
      " 'log_count/INFO': 95,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 197167, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9F6B10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29566,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6050905,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.603151,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 718732, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30367469,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 15,\n",
      " 'log_count/INFO': 135,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 115581, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D999220>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29614,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6019652,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.022481,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 727033, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30117315,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 25,\n",
      " 'log_count/INFO': 310,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 704552, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (19 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29579,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6243877,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.731928,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 731904, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30988197,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 19,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 22,\n",
      " 'log_count/INFO': 197,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 999976, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D8B8B90>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29628,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5997274,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.680809,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 740415, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29981294,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 174,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 59606, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9162D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29659,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6264722,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.588697,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 746225, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31409055,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 16,\n",
      " 'log_count/INFO': 133,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 157528, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9C8A40>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29411,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6029750,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 41.668846,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 759452, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30496121,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 20,\n",
      " 'log_count/INFO': 164,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 90606, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D96BB60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:04 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:04 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 30156,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5990815,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.187166,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 4, 768510, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29878553,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 29,\n",
      " 'log_count/INFO': 400,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 581344, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:04 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29425,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6042756,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.351839,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 137214, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30485257,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 29,\n",
      " 'log_count/INFO': 304,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 785375, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29358,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5903919,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.308669,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 144508, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29160418,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 29,\n",
      " 'log_count/INFO': 288,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 835839, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29852,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6066901,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.432363,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 152510, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30817851,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 29,\n",
      " 'log_count/INFO': 332,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 720147, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29598,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6017356,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.77941,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 632152, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30409757,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 29,\n",
      " 'log_count/INFO': 286,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 852742, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29436,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6055033,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.581504,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 803778, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30685661,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 15,\n",
      " 'log_count/INFO': 134,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 222274, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA13C50>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:05 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 30052,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6015980,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 42.593726,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 5, 925884, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30359684,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 12,\n",
      " 'log_count/INFO': 102,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 332158, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:05 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:05 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA73A70>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:06 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:06 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29450,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5975135,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 43.248055,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 6, 65190, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30010068,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 31,\n",
      " 'log_count/INFO': 318,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 817135, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:06 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29378,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5999808,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.507341,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 123484, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29990098,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 31,\n",
      " 'log_count/INFO': 412,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 616143, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29395,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6028919,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.175695,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 253436, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30549460,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 24,\n",
      " 'log_count/INFO': 213,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 77741, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9532C0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 30064,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6067602,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.223984,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 265154, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31051298,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 27,\n",
      " 'log_count/INFO': 235,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 41170, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9155E0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29725,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5972906,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.500925,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 387103, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29706169,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 33,\n",
      " 'log_count/INFO': 294,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 886178, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29536,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6332188,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.116297,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 394098, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32357121,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 17,\n",
      " 'log_count/INFO': 144,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 277801, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9F7C80>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29850,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6303649,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.641302,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 609140, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 32207256,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 32,\n",
      " 'log_count/INFO': 274,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 967838, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:07 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D8D43B0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:07 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:07 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 30478,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6254271,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.857874,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 7, 990207, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31319908,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 25,\n",
      " 'log_count/INFO': 206,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 132333, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:07 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:08 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D99B6B0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:08 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29567,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6016082,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 45.415716,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 8, 103672, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 30108939,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 36,\n",
      " 'log_count/INFO': 400,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 22, 687956, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:08 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29220,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 5960266,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 44.816135,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 8, 112022, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 29470990,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 19,\n",
      " 'log_count/INFO': 151,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 295887, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:08 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3DA53140>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2025-04-27 16:54:08 [scrapy.extensions.feedexport] INFO: Stored jsonlines feed (20 items) in: datas/hotels.jl\n",
      "2025-04-27 16:54:08 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 29909,\n",
      " 'downloader/request_count': 21,\n",
      " 'downloader/request_method_count/GET': 21,\n",
      " 'downloader/response_bytes': 6105122,\n",
      " 'downloader/response_count': 21,\n",
      " 'downloader/response_status_count/200': 21,\n",
      " 'elapsed_time_seconds': 45.117715,\n",
      " 'feedexport/success_count/FileFeedStorage': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2025, 4, 27, 14, 54, 8, 134612, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 31644166,\n",
      " 'httpcompression/response_count': 21,\n",
      " 'item_scraped_count': 20,\n",
      " 'items_per_minute': None,\n",
      " 'log_count/ERROR': 33,\n",
      " 'log_count/INFO': 272,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 21,\n",
      " 'responses_per_minute': None,\n",
      " 'scheduler/dequeued': 21,\n",
      " 'scheduler/dequeued/memory': 21,\n",
      " 'scheduler/enqueued': 21,\n",
      " 'scheduler/enqueued/memory': 21,\n",
      " 'start_time': datetime.datetime(2025, 4, 27, 14, 53, 23, 16897, tzinfo=datetime.timezone.utc)}\n",
      "2025-04-27 16:54:08 [scrapy.core.engine] INFO: Spider closed (finished)\n",
      "2025-04-27 16:54:08 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method TelnetConsole.stop_listening of <scrapy.extensions.telnet.TelnetConsole object at 0x000001CF3D9047D0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\utils\\defer.py\", line 400, in maybeDeferred_coro\n",
      "    result = f(*args, **kw)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\pydispatch\\robustapply.py\", line 55, in robustApply\n",
      "    return receiver(*arguments, **named)\n",
      "  File \"c:\\__DATA_SCIENCE__\\Anaconda\\Lib\\site-packages\\scrapy\\extensions\\telnet.py\", line 76, in stop_listening\n",
      "    self.port.stopListening()\n",
      "AttributeError: 'TelnetConsole' object has no attribute 'port'\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os \n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from variables import best_cities, hotels_jl_name\n",
    "\n",
    "\n",
    "# Classe qui hérite de scrapy.Spider, qui va permettre de scrapper Booking\n",
    "class BookingSpider(scrapy.Spider):\n",
    "\n",
    "    name = \"booking\"\n",
    "\n",
    "    def __init__(self, id_city, city, name = None, **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        self.id_city = id_city\n",
    "        self.city = city\n",
    "        \n",
    "        # URL de recherche booking la plus simple, avec 3 paramètres : \n",
    "        # la ville, le type détablissement (uniquement hôtels), triés par notes utilisateurs (puisqu'on veut le top 20 des hôtels)\n",
    "        self.start_urls = [\n",
    "            f\"https://www.booking.com/searchresults.fr.html?ss={self.city}&order=bayesian_review_score&nflt=ht_id%3D204\"\n",
    "        ]\n",
    "\n",
    "    # Parse la page de résultat de la recherche pour en extraire : \n",
    "    # le nom de l'hôtel, le lien vers sa page détaillée, la note utilisateurs\n",
    "    def parse(self, response):\n",
    "        nb_hotel = 1\n",
    "        quotes = response.xpath(\"//*[@id='bodyconstraint-inner']/div/div/div[2]/div[3]/div[2]/div[2]/div[3]/div\")\n",
    "\n",
    "        # Je boucle sur chaque rectangle de la page\n",
    "        for quote in quotes:\n",
    "            # On veut le top 20 des hôtels\n",
    "            if nb_hotel <= 20:\n",
    "                name_hotel = quote.xpath(\"div[1]/div[2]/div/div[1]/div[1]/div/div[1]/div/h3/a/div[1]/text()\").get()\n",
    "                link = response.urljoin(quote.xpath(\"div[1]/div[2]/div/div[1]/div[1]/div/div[1]/div/h3/a/@href\").get())\n",
    "                score = quote.xpath(\"div[1]/div[2]/div/div[1]/div[2]/div/div/a/span/div/div[1]/text()\").get()\n",
    "                        \n",
    "                if name_hotel and link:\n",
    "                    # On passe les informations récupérées à la fonction parse_hotel qui va scraper la page détaillée de chaque hôtel\n",
    "                    yield response.follow(link, callback=self.parse_hotel, meta={\"id_city\": self.id_city, \"city\": self.city, \"name\": name_hotel, \"link\": link, \"score\": score})\n",
    "                    nb_hotel += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # Parse la page détaillée de chaque hôtel\n",
    "    def parse_hotel(self, response):\n",
    "        # On récupère les informations passées en paramètre\n",
    "        id_city = response.meta[\"id_city\"]\n",
    "        city = response.meta[\"city\"]\n",
    "        name = response.meta[\"name\"]\n",
    "        link = response.meta[\"link\"]\n",
    "        score = response.meta[\"score\"]\n",
    "\n",
    "        description = response.xpath(\"//*[@id='basiclayout']/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/div/p[1]/text()\").get()\n",
    "        coords = latitude = response.xpath(\"//*[@id='map_trigger_header_pin']\").attrib[\"data-atlas-latlng\"]\n",
    "        \n",
    "        if description and coords:\n",
    "            description = description.replace(\"\\n\", \" \")\n",
    "            latitude = coords.split(\",\")[0]\n",
    "            longitude = coords.split(\",\")[1]\n",
    "\n",
    "            # On retroune les informations \n",
    "            yield {\n",
    "                \"id_city\": id_city,\n",
    "                \"city\": city,\n",
    "                \"hotel_name\": name,\n",
    "                \"hotel_link\": link,\n",
    "                \"hotel_score\": score,\n",
    "                \"hotel_description\": description,\n",
    "                \"hotel_lat\": latitude,\n",
    "                \"hotel_lon\": longitude\n",
    "            }\n",
    "\n",
    "# On stocke les résultats du scrapping dans un fichier .jl (json lines), chaque ligne est un objet json\n",
    "# Supprimer le fichier s\"il existe déjà dans le répertoire courant\n",
    "if os.path.exists(hotels_jl_name):\n",
    "    os.remove(hotels_jl_name)\n",
    "\n",
    "process = CrawlerProcess(settings = {\n",
    "    \"USER_AGENT\": \"Chrome/97.0\",\n",
    "    \"LOG_LEVEL\": logging.INFO,\n",
    "    # jsonlines car je lance plusieurs crawler en même temps, ici chaque élément va être écrit sur une ligne indépendante\n",
    "    \"FEEDS\": {hotels_jl_name : {\"format\": \"jsonlines\", \"encoding\": \"utf-8\"}}\n",
    "})\n",
    "\n",
    "# Scrappe Booking pour chaque ville\n",
    "for i in range(len(best_cities)): \n",
    "    process.crawl(BookingSpider, id_city = i + 1, city = best_cities[i])\n",
    "\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
