{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecceb386",
   "metadata": {},
   "source": [
    "Scrape le site booking.com pour avoir le Top 20 des hôtels par ville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2526b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os \n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from variables import best_cities, hotels_jl_name\n",
    "\n",
    "\n",
    "# Classe qui hérite de scrapy.Spider, qui va permettre de scrapper Booking\n",
    "class BookingSpider(scrapy.Spider):\n",
    "\n",
    "    name = \"booking\"\n",
    "\n",
    "    def __init__(self, id_city, city, name = None, **kwargs):\n",
    "        super().__init__(name, **kwargs)\n",
    "        self.id_city = id_city\n",
    "        self.city = city\n",
    "        \n",
    "        # URL de recherche booking la plus simple, avec 3 paramètres : \n",
    "        # la ville, le type détablissement (uniquement hôtels), triés par notes utilisateurs (puisqu'on veut le top 20 des hôtels)\n",
    "        self.start_urls = [\n",
    "            f\"https://www.booking.com/searchresults.fr.html?ss={self.city}&order=bayesian_review_score&nflt=ht_id%3D204\"\n",
    "        ]\n",
    "\n",
    "    # Parse la page de résultat de la recherche pour en extraire : \n",
    "    # le nom de l'hôtel, le lien vers sa page détaillée, la note utilisateurs\n",
    "    def parse(self, response):\n",
    "        nb_hotel = 1\n",
    "        quotes = response.xpath(\"//*[@id='bodyconstraint-inner']/div/div/div[2]/div[3]/div[2]/div[2]/div[3]/div\")\n",
    "\n",
    "        # Je boucle sur chaque rectangle de la page\n",
    "        for quote in quotes:\n",
    "            # On veut le top 20 des hôtels\n",
    "            if nb_hotel <= 20:\n",
    "                name_hotel = quote.xpath(\"div[1]/div[2]/div/div[1]/div[1]/div/div[1]/div/h3/a/div[1]/text()\").get()\n",
    "                link = response.urljoin(quote.xpath(\"div[1]/div[2]/div/div[1]/div[1]/div/div[1]/div/h3/a/@href\").get())\n",
    "                score = quote.xpath(\"div[1]/div[2]/div/div[1]/div[2]/div/div/a/span/div/div[2]/text()\").get()\n",
    "                        \n",
    "                if name_hotel and link:\n",
    "                    # On passe les informations récupérées à la fonction parse_hotel qui va scraper la page détaillée de chaque hôtel\n",
    "                    yield response.follow(link, callback=self.parse_hotel, meta={\"id_city\": self.id_city, \"city\": self.city, \"name\": name_hotel, \"link\": link, \"score\": score})\n",
    "                    nb_hotel += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    # Parse la page détaillée de chaque hôtel\n",
    "    def parse_hotel(self, response):\n",
    "        # On récupère les informations passées en paramètre\n",
    "        id_city = response.meta[\"id_city\"]\n",
    "        city = response.meta[\"city\"]\n",
    "        name = response.meta[\"name\"]\n",
    "        link = response.meta[\"link\"]\n",
    "        score = response.meta[\"score\"]\n",
    "\n",
    "        description = response.xpath(\"//*[@id='basiclayout']/div[1]/div[2]/div/div[1]/div[1]/div[1]/div/div/p[1]/text()\").get()\n",
    "        coords = latitude = response.xpath(\"//*[@id='map_trigger_header_pin']\").attrib[\"data-atlas-latlng\"]\n",
    "        \n",
    "        if description and coords:\n",
    "            description = description.replace(\"\\n\", \" \")\n",
    "            latitude = coords.split(\",\")[0]\n",
    "            longitude = coords.split(\",\")[1]\n",
    "\n",
    "            # On retroune les informations \n",
    "            yield {\n",
    "                \"id_city\": id_city,\n",
    "                \"city\": city,\n",
    "                \"hotel_name\": name,\n",
    "                \"hotel_link\": link,\n",
    "                \"hotel_score\": score,\n",
    "                \"hotel_description\": description,\n",
    "                \"hotel_lat\": latitude,\n",
    "                \"hotel_lon\": longitude\n",
    "            }\n",
    "\n",
    "# On stocke les résultats du scrapping dans un fichier .jl (json lines), chaque ligne est un objet json\n",
    "# Supprimer le fichier s\"il existe déjà dans le répertoire courant\n",
    "if os.path.exists(hotels_jl_name):\n",
    "    os.remove(hotels_jl_name)\n",
    "\n",
    "process = CrawlerProcess(settings = {\n",
    "    \"USER_AGENT\": \"Chrome/97.0\",\n",
    "    \"LOG_LEVEL\": logging.INFO,\n",
    "    # jsonlines car je lance plusieurs crawler en même temps, ici chaque élément va être écrit sur une ligne indépendante\n",
    "    \"FEEDS\": {hotels_jl_name : {\"format\": \"jsonlines\", \"encoding\": \"utf-8\"}}\n",
    "})\n",
    "\n",
    "# Scrappe Booking pour chaque ville\n",
    "for i in range(len(best_cities)): \n",
    "    process.crawl(BookingSpider, id_city = i + 1, city = best_cities[i])\n",
    "\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsfs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
